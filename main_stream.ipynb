{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-20 13:10:47,089] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-05-20 13:10:47,368] torch.distributed.elastic.multiprocessing.redirects: [WARNING] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "[2024-05-20 13:11:09,635] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0+ce78a63, git-hash=ce78a63, git-branch=master\n",
      "[2024-05-20 13:11:09,635] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter replace_method is deprecated. This parameter is no longer needed, please remove from your call to DeepSpeed-inference\n",
      "[2024-05-20 13:11:09,635] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter mp_size is deprecated use tensor_parallel.tp_size instead\n",
      "[2024-05-20 13:11:09,635] [INFO] [logging.py:96:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1\n",
      "[2024-05-20 13:11:09,848] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 1024, 'intermediate_size': 4096, 'heads': 16, 'num_hidden_layers': -1, 'dtype': torch.float32, 'pre_layer_norm': True, 'norm_type': <NormType.LayerNorm: 1>, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 1, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': -1, 'rotate_half': False, 'rotate_every_two': True, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.GELU: 1>, 'specialized_mode': False, 'training_mp_size': 1, 'bigscience_bloom': False, 'max_out_tokens': 1024, 'min_out_tokens': 1, 'scale_attn_by_inverse_layer_idx': False, 'enable_qkv_quantization': False, 'use_mup': False, 'return_single_tuple': False, 'set_empty_params': False, 'transposed_mode': False, 'use_triton': False, 'triton_autotune': False, 'num_kv': -1, 'rope_theta': 10000}\n"
     ]
    }
   ],
   "source": [
    "from models.TTS_utils import load_manual_xtts_v2\n",
    "config_path = \"C:/tmp/xtts_ft/run/training/GPT_XTTS_FT-April-02-2024_05+08PM-0000000/config.json\"\n",
    "model_path = \"C:/tmp/xtts_ft/run/training/GPT_XTTS_FT-April-02-2024_05+08PM-0000000\"\n",
    "\n",
    "xtts_v2_model = load_manual_xtts_v2(config_path, model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "[('Oye, ¿qué pasa hermano? ¿Cómo estás?', 0, 'audio_segments\\\\segment_0.wav', 'results\\\\result_0.wav', 'es')]\n",
      "Processing text 0: Oye, ¿qué pasa hermano? ¿Cómo estás?\n",
      "Processing text 0: es\n",
      "0\n",
      "Time to first chunk: 0.5872609615325928\n",
      "Received chunk 0 of audio length 45568\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_0_0.wav\n",
      "Received chunk 1 of audio length 22272\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_1_0.wav\n",
      "Total audio length: 22272\n",
      "Audio playback finished.\n",
      "Inference...\n",
      "[('¿ Qué pasa?', 1, 'audio_segments\\\\segment_1.wav', 'results\\\\result_1.wav', 'es')]\n",
      "Processing text 1: ¿ Qué pasa?\n",
      "Processing text 1: es\n",
      "1\n",
      "Time to first chunk: 0.5510299205780029\n",
      "Received chunk 0 of audio length 45568\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_0_1.wav\n",
      "Received chunk 1 of audio length 14592\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_1_1.wav\n",
      "Total audio length: 60160\n",
      "Audio playback finished.\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mTTS_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stream_prod\n\u001b[1;32m----> 2\u001b[0m \u001b[43mstream_prod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxtts_v2_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecord_temp.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio_segments/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\spn\\Desktop\\IE_Last_year\\main_capstone\\models\\TTS_utils.py:186\u001b[0m, in \u001b[0;36mstream_prod\u001b[1;34m(model, json_path, directory_path)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;129;01mis\u001b[39;00m  \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m--> 186\u001b[0m     \u001b[43mstream_prod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirectory_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStreaming finished\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\spn\\Desktop\\IE_Last_year\\main_capstone\\models\\TTS_utils.py:186\u001b[0m, in \u001b[0;36mstream_prod\u001b[1;34m(model, json_path, directory_path)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;129;01mis\u001b[39;00m  \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m--> 186\u001b[0m     \u001b[43mstream_prod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirectory_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStreaming finished\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "    \u001b[1;31m[... skipping similar frames: stream_prod at line 186 (3 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\spn\\Desktop\\IE_Last_year\\main_capstone\\models\\TTS_utils.py:186\u001b[0m, in \u001b[0;36mstream_prod\u001b[1;34m(model, json_path, directory_path)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;129;01mis\u001b[39;00m  \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m--> 186\u001b[0m     \u001b[43mstream_prod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirectory_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStreaming finished\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\spn\\Desktop\\IE_Last_year\\main_capstone\\models\\TTS_utils.py:185\u001b[0m, in \u001b[0;36mstream_prod\u001b[1;34m(model, json_path, directory_path)\u001b[0m\n\u001b[0;32m    183\u001b[0m results \u001b[38;5;241m=\u001b[39m streamer\u001b[38;5;241m.\u001b[39minference_and_play(json_path, directory_path)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;129;01mis\u001b[39;00m  \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 185\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m    186\u001b[0m     stream_prod(model, json_path, directory_path)\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStreaming finished\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from models.TTS_utils import stream_prod\n",
    "stream_prod(xtts_v2_model, \"record_temp.json\", \"audio_segments/\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
