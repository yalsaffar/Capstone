{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\spn\\anaconda3\\envs\\capstone\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\spn\\anaconda3\\envs\\capstone\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\spn\\anaconda3\\envs\\capstone\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "[2024-04-11 16:11:14,200] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-11 16:11:14,655] torch.distributed.elastic.multiprocessing.redirects: [WARNING] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-11 16:11:14,996] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0+ce78a63, git-hash=ce78a63, git-branch=master\n",
      "[2024-04-11 16:11:14,998] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter replace_method is deprecated. This parameter is no longer needed, please remove from your call to DeepSpeed-inference\n",
      "[2024-04-11 16:11:14,999] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter mp_size is deprecated use tensor_parallel.tp_size instead\n",
      "[2024-04-11 16:11:15,000] [INFO] [logging.py:96:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1\n",
      "[2024-04-11 16:11:15,195] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 1024, 'intermediate_size': 4096, 'heads': 16, 'num_hidden_layers': -1, 'dtype': torch.float32, 'pre_layer_norm': True, 'norm_type': <NormType.LayerNorm: 1>, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 1, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': -1, 'rotate_half': False, 'rotate_every_two': True, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.GELU: 1>, 'specialized_mode': False, 'training_mp_size': 1, 'bigscience_bloom': False, 'max_out_tokens': 1024, 'min_out_tokens': 1, 'scale_attn_by_inverse_layer_idx': False, 'enable_qkv_quantization': False, 'use_mup': False, 'return_single_tuple': False, 'set_empty_params': False, 'transposed_mode': False, 'use_triton': False, 'triton_autotune': False, 'num_kv': -1, 'rope_theta': 10000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\spn\\anaconda3\\envs\\capstone\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from models.TTS_utils import load_manual_xtts_v2\n",
    "config_path = \"C:/tmp/xtts_ft/run/training/GPT_XTTS_FT-April-02-2024_05+08PM-0000000/config.json\"\n",
    "model_path = \"C:/tmp/xtts_ft/run/training/GPT_XTTS_FT-April-02-2024_05+08PM-0000000\"\n",
    "\n",
    "xtts_v2_model = load_manual_xtts_v2(config_path, model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "[('Hola, ¿ qué pasa?', 0, 'audio_segments\\\\segment_0.wav', 'results\\\\result_0.wav', 'es')]\n",
      "Processing text 0: Hola, ¿ qué pasa?\n",
      "Processing text 0: es\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\spn\\anaconda3\\envs\\capstone\\Lib\\site-packages\\TTS\\tts\\layers\\xtts\\stream_generator.py:138: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to first chunk: 1.691728115081787\n",
      "Received chunk 0 of audio length 45568\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_0_0.wav\n",
      "Received chunk 1 of audio length 6656\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_1_0.wav\n",
      "Total audio length: 6656\n",
      "Audio playback finished.\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "[('Así que está funcionando muy bien.', 3, 'audio_segments\\\\segment_3.wav', 'results\\\\result_3.wav', 'es')]\n",
      "Processing text 3: Así que está funcionando muy bien.\n",
      "Processing text 3: es\n",
      "3\n",
      "Time to first chunk: 0.5994141101837158\n",
      "Received chunk 0 of audio length 45568\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_0_3.wav\n",
      "Received chunk 1 of audio length 37888\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_1_3.wav\n",
      "Total audio length: 37888\n",
      "Audio playback finished.\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "[('- Lo siento.', 8, 'audio_segments\\\\segment_8.wav', 'results\\\\result_8.wav', 'es')]\n",
      "Processing text 8: - Lo siento.\n",
      "Processing text 8: es\n",
      "8\n",
      "Time to first chunk: 0.43991684913635254\n",
      "Received chunk 0 of audio length 21248\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_0_8.wav\n",
      "Total audio length: 0\n",
      "Audio playback finished.\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "[('Creo que está funcionando y estoy', 9, 'audio_segments\\\\segment_9.wav', 'results\\\\result_9.wav', 'es')]\n",
      "Processing text 9: Creo que está funcionando y estoy\n",
      "Processing text 9: es\n",
      "9\n",
      "Time to first chunk: 0.6407654285430908\n",
      "Received chunk 0 of audio length 44544\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_0_9.wav\n",
      "Total audio length: 0\n",
      "Audio playback finished.\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "[('y la cancelación de ruido funciona bien', 17, 'audio_segments\\\\segment_17.wav', 'results\\\\result_17.wav', 'es')]\n",
      "Processing text 17: y la cancelación de ruido funciona bien\n",
      "Processing text 17: es\n",
      "17\n",
      "Time to first chunk: 0.5555355548858643\n",
      "Received chunk 0 of audio length 45568\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_0_17.wav\n",
      "Received chunk 1 of audio length 31232\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_1_17.wav\n",
      "Total audio length: 31232\n",
      "Audio playback finished.\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "[('Es increíble.', 21, 'audio_segments\\\\segment_21.wav', 'results\\\\result_21.wav', 'es')]\n",
      "Processing text 21: Es increíble.\n",
      "Processing text 21: es\n",
      "21\n",
      "Time to first chunk: 0.6688621044158936\n",
      "Received chunk 0 of audio length 45568\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_0_21.wav\n",
      "Received chunk 1 of audio length 21248\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_1_21.wav\n",
      "Total audio length: 21248\n",
      "Audio playback finished.\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "[('Es perfecto.', 24, 'audio_segments\\\\segment_24.wav', 'results\\\\result_24.wav', 'es')]\n",
      "Processing text 24: Es perfecto.\n",
      "Processing text 24: es\n",
      "24\n",
      "Time to first chunk: 0.6060965061187744\n",
      "Received chunk 0 of audio length 34560\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_0_24.wav\n",
      "Total audio length: 0\n",
      "Audio playback finished.\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "[('La aplicación funciona perfectamente', 65, 'audio_segments\\\\segment_65.wav', 'results\\\\result_65.wav', 'es')]\n",
      "Processing text 65: La aplicación funciona perfectamente\n",
      "Processing text 65: es\n",
      "65\n",
      "Time to first chunk: 0.6061224937438965\n",
      "Received chunk 0 of audio length 45568\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_0_65.wav\n",
      "Received chunk 1 of audio length 22272\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_1_65.wav\n",
      "Total audio length: 22272\n",
      "Audio playback finished.\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "[('Muy guay muy genial', 68, 'audio_segments\\\\segment_68.wav', 'results\\\\result_68.wav', 'es')]\n",
      "Processing text 68: Muy guay muy genial\n",
      "Processing text 68: es\n",
      "68\n",
      "Time to first chunk: 0.6031913757324219\n",
      "Received chunk 0 of audio length 40192\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_0_68.wav\n",
      "Total audio length: 0\n",
      "Audio playback finished.\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "[('- ¿ Qué?', 71, 'audio_segments\\\\segment_71.wav', 'results\\\\result_71.wav', 'es')]\n",
      "Processing text 71: - ¿ Qué?\n",
      "Processing text 71: es\n",
      "71\n",
      "Time to first chunk: 0.5653460025787354\n",
      "Received chunk 0 of audio length 45568\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_0_71.wav\n",
      "Received chunk 1 of audio length 3328\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_1_71.wav\n",
      "Total audio length: 3328\n",
      "Audio playback finished.\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "[('El', 112, 'audio_segments\\\\segment_112.wav', 'results\\\\result_112.wav', 'es')]\n",
      "Processing text 112: El\n",
      "Processing text 112: es\n",
      "112\n",
      "Time to first chunk: 0.5392861366271973\n",
      "Received chunk 0 of audio length 45568\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_0_112.wav\n",
      "Received chunk 1 of audio length 46848\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_1_112.wav\n",
      "Received chunk 2 of audio length 7936\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_2_112.wav\n",
      "Total audio length: 54784\n",
      "Audio playback finished.\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "[('Así que me las arreglé para hacer que el modelo funcione bastante rápido bastante rápido y está funcionando ahora si quieres probarlo', 115, 'audio_segments\\\\segment_115.wav', 'results\\\\result_115.wav', 'es')]\n",
      "Processing text 115: Así que me las arreglé para hacer que el modelo funcione bastante rápido bastante rápido y está funcionando ahora si quieres probarlo\n",
      "Processing text 115: es\n",
      "115\n",
      "Time to first chunk: 0.5923347473144531\n",
      "Received chunk 0 of audio length 45568\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_0_115.wav\n",
      "Received chunk 1 of audio length 46848\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_1_115.wav\n",
      "Received chunk 2 of audio length 46848\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_2_115.wav\n",
      "Received chunk 3 of audio length 46848\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_3_115.wav\n",
      "Received chunk 4 of audio length 46848\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_4_115.wav\n",
      "Received chunk 5 of audio length 18944\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_5_115.wav\n",
      "Total audio length: 206336\n",
      "Audio playback finished.\n",
      "Inference...\n",
      "[('Está bien, en realidad está diciendo lo que acabo de decir.', 117, 'audio_segments\\\\segment_117.wav', 'results\\\\result_117.wav', 'es'), ('Así que lo que hice sólo para darte un poco de antecedentes', 125, 'audio_segments\\\\segment_125.wav', 'results\\\\result_125.wav', 'es')]\n",
      "Processing text 117: Está bien, en realidad está diciendo lo que acabo de decir.\n",
      "Processing text 117: es\n",
      "Processing text 125: Así que lo que hice sólo para darte un poco de antecedentes\n",
      "Processing text 125: es\n",
      "117\n",
      "Time to first chunk: 0.5767788887023926\n",
      "Received chunk 0 of audio length 45568\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_0_117.wav\n",
      "Received chunk 1 of audio length 46848\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_1_117.wav\n",
      "Received chunk 2 of audio length 31232\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_2_117.wav\n",
      "Total audio length: 123648\n",
      "Audio playback finished.\n",
      "125\n",
      "Time to first chunk: 0.8717293739318848\n",
      "Received chunk 0 of audio length 45568\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_0_125.wav\n",
      "Received chunk 1 of audio length 46848\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_1_125.wav\n",
      "Received chunk 2 of audio length 22272\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_2_125.wav\n",
      "Total audio length: 114688\n",
      "Audio playback finished.\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "[('Tuve un problema con la latencia porque el modelo de texto a voz fue tomado mucho mucho voy a parar sólo amable y seguir escu', 126, 'audio_segments\\\\segment_126.wav', 'results\\\\result_126.wav', 'es')]\n",
      "Processing text 126: Tuve un problema con la latencia porque el modelo de texto a voz fue tomado mucho mucho voy a parar sólo amable y seguir escu\n",
      "Processing text 126: es\n",
      "126\n",
      "Time to first chunk: 0.5461115837097168\n",
      "Received chunk 0 of audio length 45568\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_0_126.wav\n",
      "Received chunk 1 of audio length 46848\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_1_126.wav\n",
      "Received chunk 2 of audio length 46848\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_2_126.wav\n",
      "Received chunk 3 of audio length 46848\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_3_126.wav\n",
      "Received chunk 4 of audio length 46848\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_4_126.wav\n",
      "Received chunk 5 of audio length 8960\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_5_126.wav\n",
      "Total audio length: 196352\n",
      "Audio playback finished.\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "[('Está bien, ¿está funcionando razonablemente bien o qué?', 2, 'audio_segments\\\\segment_2.wav', 'results\\\\result_2.wav', 'es')]\n",
      "Processing text 2: Está bien, ¿está funcionando razonablemente bien o qué?\n",
      "Processing text 2: es\n",
      "2\n",
      "Time to first chunk: 0.5427591800689697\n",
      "Received chunk 0 of audio length 45568\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_0_2.wav\n",
      "Received chunk 1 of audio length 46848\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_1_2.wav\n",
      "Received chunk 2 of audio length 31232\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_2_2.wav\n",
      "Total audio length: 78080\n",
      "Audio playback finished.\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "[('Está bien, es como si tuviera un \"l\" un poco agradable para ir con pero ya es es bastante bueno', 6, 'audio_segments\\\\segment_6.wav', 'results\\\\result_6.wav', 'es')]\n",
      "Processing text 6: Está bien, es como si tuviera un \"l\" un poco agradable para ir con pero ya es es bastante bueno\n",
      "Processing text 6: es\n",
      "6\n",
      "Time to first chunk: 0.5690882205963135\n",
      "Received chunk 0 of audio length 45568\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_0_6.wav\n",
      "Received chunk 1 of audio length 46848\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_1_6.wav\n",
      "Received chunk 2 of audio length 46848\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_2_6.wav\n",
      "Received chunk 3 of audio length 46848\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_3_6.wav\n",
      "Received chunk 4 of audio length 46848\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_4_6.wav\n",
      "Received chunk 5 of audio length 31232\n",
      "24000\n",
      "Chunk saved as audio_segments/chunk_5_6.wav\n",
      "Total audio length: 218624\n",
      "Audio playback finished.\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n",
      "Inference...\n",
      "No more text to process\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mTTS_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stream_prod\n\u001b[1;32m----> 2\u001b[0m \u001b[43mstream_prod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxtts_v2_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecord_temp.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio_segments/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\spn\\Desktop\\IE_Last_year\\main_capstone\\models\\TTS_utils.py:186\u001b[0m, in \u001b[0;36mstream_prod\u001b[1;34m(model, json_path, directory_path)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;129;01mis\u001b[39;00m  \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m--> 186\u001b[0m     \u001b[43mstream_prod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirectory_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStreaming finished\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\spn\\Desktop\\IE_Last_year\\main_capstone\\models\\TTS_utils.py:186\u001b[0m, in \u001b[0;36mstream_prod\u001b[1;34m(model, json_path, directory_path)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;129;01mis\u001b[39;00m  \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m--> 186\u001b[0m     \u001b[43mstream_prod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirectory_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStreaming finished\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "    \u001b[1;31m[... skipping similar frames: stream_prod at line 186 (977 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\spn\\Desktop\\IE_Last_year\\main_capstone\\models\\TTS_utils.py:186\u001b[0m, in \u001b[0;36mstream_prod\u001b[1;34m(model, json_path, directory_path)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;129;01mis\u001b[39;00m  \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m--> 186\u001b[0m     \u001b[43mstream_prod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirectory_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStreaming finished\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\spn\\Desktop\\IE_Last_year\\main_capstone\\models\\TTS_utils.py:185\u001b[0m, in \u001b[0;36mstream_prod\u001b[1;34m(model, json_path, directory_path)\u001b[0m\n\u001b[0;32m    183\u001b[0m results \u001b[38;5;241m=\u001b[39m streamer\u001b[38;5;241m.\u001b[39minference_and_play(json_path, directory_path)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;129;01mis\u001b[39;00m  \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 185\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m    186\u001b[0m     stream_prod(model, json_path, directory_path)\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStreaming finished\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from models.TTS_utils import stream_prod\n",
    "stream_prod(xtts_v2_model, \"record_temp.json\", \"audio_segments/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\spn\\anaconda3\\envs\\capstone\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\spn\\anaconda3\\envs\\capstone\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\spn\\anaconda3\\envs\\capstone\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "[2024-04-12 16:09:06,325] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-12 16:09:06,808] torch.distributed.elastic.multiprocessing.redirects: [WARNING] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-12 16:09:07,252] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0+ce78a63, git-hash=ce78a63, git-branch=master\n",
      "[2024-04-12 16:09:07,254] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter replace_method is deprecated. This parameter is no longer needed, please remove from your call to DeepSpeed-inference\n",
      "[2024-04-12 16:09:07,254] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter mp_size is deprecated use tensor_parallel.tp_size instead\n",
      "[2024-04-12 16:09:07,254] [INFO] [logging.py:96:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1\n",
      "[2024-04-12 16:09:07,495] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 1024, 'intermediate_size': 4096, 'heads': 16, 'num_hidden_layers': -1, 'dtype': torch.float32, 'pre_layer_norm': True, 'norm_type': <NormType.LayerNorm: 1>, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 1, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': -1, 'rotate_half': False, 'rotate_every_two': True, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.GELU: 1>, 'specialized_mode': False, 'training_mp_size': 1, 'bigscience_bloom': False, 'max_out_tokens': 1024, 'min_out_tokens': 1, 'scale_attn_by_inverse_layer_idx': False, 'enable_qkv_quantization': False, 'use_mup': False, 'return_single_tuple': False, 'set_empty_params': False, 'transposed_mode': False, 'use_triton': False, 'triton_autotune': False, 'num_kv': -1, 'rope_theta': 10000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\spn\\anaconda3\\envs\\capstone\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from models.TTS_utils import load_manual_xtts_v2\n",
    "config_path = \"C:/tmp/xtts_ft/run/training/GPT_XTTS_FT-April-02-2024_05+08PM-0000000/config.json\"\n",
    "model_path = \"C:/tmp/xtts_ft/run/training/GPT_XTTS_FT-April-02-2024_05+08PM-0000000\"\n",
    "\n",
    "xtts_v2_model = load_manual_xtts_v2(config_path, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
