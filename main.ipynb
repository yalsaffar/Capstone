{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-04-11 16:14:56 nemo_logging:381] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-04-11 16:14:56 nemo_logging:393] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /disk1/NVIDIA/datasets/LibriSpeech_NeMo/librivox-train-all.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 16.7\n",
      "    min_duration: 0.1\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    shuffle_n: 2048\n",
      "    bucketing_strategy: fully_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2024-04-11 16:14:56 nemo_logging:393] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /disk1/NVIDIA/datasets/LibriSpeech_NeMo/librivox-dev-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    use_start_end_token: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2024-04-11 16:14:56 nemo_logging:393] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    use_start_end_token: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-04-11 16:14:56 nemo_logging:381] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-04-11 16:14:59 nemo_logging:393] `method_cfg` is deprecated and will be removed in the future. Please use `measure_cfg` instead.\n",
      "[NeMo W 2024-04-11 16:14:59 nemo_logging:393] Re-writing `measure_cfg` with the value of `method_cfg`.\n",
      "[NeMo W 2024-04-11 16:14:59 nemo_logging:393] `temperature` is deprecated and will be removed in the future. Please use `alpha` instead.\n",
      "[NeMo W 2024-04-11 16:14:59 nemo_logging:393] Re-writing `alpha` with the value of `temperature`.\n",
      "[NeMo W 2024-04-11 16:14:59 nemo_logging:393] `method_cfg` is deprecated and will be removed in the future. Please use `measure_cfg` instead.\n",
      "[NeMo W 2024-04-11 16:14:59 nemo_logging:393] Re-writing `measure_cfg` with the value of `method_cfg`.\n",
      "[NeMo W 2024-04-11 16:14:59 nemo_logging:393] `temperature` is deprecated and will be removed in the future. Please use `alpha` instead.\n",
      "[NeMo W 2024-04-11 16:14:59 nemo_logging:393] Re-writing `alpha` with the value of `temperature`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-04-11 16:15:01 nemo_logging:381] Model EncDecCTCModelBPE was successfully restored from C:\\Users\\spn\\.cache\\huggingface\\hub\\models--nvidia--parakeet-ctc-0.6b\\snapshots\\097ffc5b027beabc73acb627def2d1d278e774e9\\parakeet-ctc-0.6b.nemo.\n"
     ]
    }
   ],
   "source": [
    "from models.nllb import nllb\n",
    "#from models.TTS_utils import xtts_v2\n",
    "from models.parakeet import parakeet_ctc_model\n",
    "from models.es_fastconformer import stt_es_model\n",
    "model_nllb, tokinizer_nllb = nllb()\n",
    "#xtts_v2_model = xtts_v2()\n",
    "parakeet = parakeet_ctc_model()\n",
    "#sst = stt_es_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing audio_segments\\segment_0.wav...\n",
      "Processing segment...\n",
      "0.0020072865\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_1.wav...\n",
      "Processing segment...\n",
      "0.0014216166\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_2.wav...\n",
      "Processing segment...\n",
      "0.054265257\n",
      "Noise reduction done!\n",
      "Noise removed. Time: 0.03545737266540527\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be4f21f5103041229913ce6b4dcd9ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: okay is this working reasonably well or what\n",
      "Transcription time: 0.7581398487091064\n",
      "Translating...\n",
      "Processing translation...\n",
      "Writing audio_segments\\segment_3.wav...\n",
      "Processing segment...\n",
      "0.0060705054\n",
      "No speech detected.\n",
      "Translation: Está bien, ¿está funcionando razonablemente bien o qué?\n",
      "Translation time: 6.934861183166504\n",
      "Writing audio_segments\\segment_4.wav...\n",
      "Processing segment...\n",
      "0.0020674649\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_5.wav...\n",
      "Processing segment...\n",
      "0.0015129801\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_6.wav...\n",
      "Processing segment...\n",
      "0.042173203\n",
      "Noise reduction done!\n",
      "Noise removed. Time: 0.04321742057800293\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f56fca7f3447098f636725ac1fff5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: okay it's kind of like it has a l a l bit a nice to go with but ya it's it's quite good\n",
      "Transcription time: 0.6980593204498291\n",
      "Translating...\n",
      "Processing translation...\n",
      "Translation: Está bien, es como si tuviera un \"l\" un poco agradable para ir con pero ya es es bastante bueno\n",
      "Translation time: 9.96947979927063\n",
      "Writing audio_segments\\segment_7.wav...\n",
      "Processing segment...\n",
      "0.00492581\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_8.wav...\n",
      "Processing segment...\n",
      "0.0015228179\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_9.wav...\n",
      "Processing segment...\n",
      "0.0033476064\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_10.wav...\n",
      "Processing segment...\n",
      "0.004520827\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_11.wav...\n",
      "Processing segment...\n",
      "0.007115867\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_12.wav...\n",
      "Processing segment...\n",
      "0.0023570245\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_13.wav...\n",
      "Processing segment...\n",
      "0.012355573\n",
      "No speech detected.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstream_VAD\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stream\n\u001b[1;32m----> 2\u001b[0m \u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparakeet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_nllb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokinizer_nllb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43menglish\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspanish\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecord_temp.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecord_per.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\spn\\Desktop\\IE_Last_year\\main_capstone\\stream_VAD.py:158\u001b[0m, in \u001b[0;36mstream\u001b[1;34m(asr_model, model_nllb, tokinizer_nllb, source_lang, target_lang, json_file_temp, json_file_record)\u001b[0m\n\u001b[0;32m    154\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(result_dir)\n\u001b[0;32m    156\u001b[0m executor \u001b[38;5;241m=\u001b[39m ThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Adjust the number of workers as per your requirement\u001b[39;00m\n\u001b[1;32m--> 158\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvad_collector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCHUNK_DURATION_MS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPADDING_DURATION_MS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_segements\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegments_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msegment_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_results\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresult_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\spn\\Desktop\\IE_Last_year\\main_capstone\\stream_VAD.py:36\u001b[0m, in \u001b[0;36mvad_collector\u001b[1;34m(sample_rate, frame_duration_ms, padding_duration_ms, vad, frames)\u001b[0m\n\u001b[0;32m     33\u001b[0m triggered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     35\u001b[0m voiced_frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 36\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_speech\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_speech\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtriggered\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\spn\\Desktop\\IE_Last_year\\main_capstone\\stream_VAD.py:147\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    145\u001b[0m stream \u001b[38;5;241m=\u001b[39m audio\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mFORMAT, channels\u001b[38;5;241m=\u001b[39mCHANNELS, rate\u001b[38;5;241m=\u001b[39mRATE, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, frames_per_buffer\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m160\u001b[39m)\n\u001b[0;32m    146\u001b[0m frames \u001b[38;5;241m=\u001b[39m read_audio(stream, CHUNK_DURATION_MS, RATE)\n\u001b[1;32m--> 147\u001b[0m frames \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m segments_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio_segments\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    150\u001b[0m result_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\spn\\Desktop\\IE_Last_year\\main_capstone\\stream_VAD.py:27\u001b[0m, in \u001b[0;36mread_audio\u001b[1;34m(stream, frame_duration_ms, rate)\u001b[0m\n\u001b[0;32m     25\u001b[0m frames_per_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(rate \u001b[38;5;241m*\u001b[39m frame_duration_ms \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes_per_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\spn\\anaconda3\\envs\\capstone\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from stream_VAD import stream\n",
    "stream(parakeet, model_nllb, tokinizer_nllb, \"english\", \"spanish\", 'record_temp.json', 'record_per.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc0440dfcaf4c9f814689fc47c10e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)tt_es_fastconformer_hybrid_large_pc.nemo:   0%|          | 0.00/459M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-04-12 16:10:09 nemo_logging:381] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-04-12 16:10:10 nemo_logging:393] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20\n",
      "    min_duration: 0.1\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    shuffle_n: 2048\n",
      "    bucketing_strategy: fully_randomized\n",
      "    bucketing_batch_size: null\n",
      "    is_concat: false\n",
      "    concat_sampling_technique: random\n",
      "    concat_sampling_probabilities: ''\n",
      "    \n",
      "[NeMo W 2024-04-12 16:10:10 nemo_logging:393] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    is_concat: true\n",
      "    concat_sampling_technique: random\n",
      "    concat_sampling_probabilities:\n",
      "    - 0.099\n",
      "    - 0.2771\n",
      "    - 0.5482\n",
      "    - 0.0757\n",
      "    concat_shuffle: false\n",
      "    concat_sampling_seed: 1234\n",
      "    max_duration: 20\n",
      "    \n",
      "[NeMo W 2024-04-12 16:10:10 nemo_logging:393] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-04-12 16:10:10 nemo_logging:381] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-04-12 16:10:11 nemo_logging:393] c:\\Users\\spn\\anaconda3\\envs\\capstone\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "      warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-04-12 16:10:11 nemo_logging:381] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2024-04-12 16:10:12 nemo_logging:381] Model EncDecHybridRNNTCTCBPEModel was successfully restored from C:\\Users\\spn\\.cache\\huggingface\\hub\\models--nvidia--stt_es_fastconformer_hybrid_large_pc\\snapshots\\65f775445d5947d6784c3e80d9a14d859571947f\\stt_es_fastconformer_hybrid_large_pc.nemo.\n"
     ]
    }
   ],
   "source": [
    "from models.es_fastconformer import stt_es_model\n",
    "model = stt_es_model()\n",
    "# check how much memory is used by the model\n",
    "import torch\n",
    "import psutil\n",
    "import os\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 458.86 MB\n"
     ]
    }
   ],
   "source": [
    "# get the size of the model in term of memory in MB\n",
    "def get_size(model):\n",
    "    torch.save(model.state_dict(), 'temp.p')\n",
    "    size = os.path.getsize('temp.p') / 1e6\n",
    "    os.remove('temp.p')\n",
    "    return size\n",
    "size = get_size(model)\n",
    "print(f\"Model size: {size:.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
