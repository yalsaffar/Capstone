{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\spn\\anaconda3\\envs\\capstone\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\spn\\anaconda3\\envs\\capstone\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\spn\\anaconda3\\envs\\capstone\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "[NeMo W 2024-04-05 16:01:55 nemo_logging:393] c:\\Users\\spn\\anaconda3\\envs\\capstone\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "      _torch_pytree._register_pytree_node(\n",
      "    \n",
      "[NeMo W 2024-04-05 16:01:55 nemo_logging:393] Could not import NeMo NLP collection which is required for speech translation model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.\n",
      " > Using model: xtts\n",
      "[NeMo I 2024-04-05 16:02:27 nemo_logging:381] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-04-05 16:02:27 nemo_logging:393] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /disk1/NVIDIA/datasets/LibriSpeech_NeMo/librivox-train-all.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 16.7\n",
      "    min_duration: 0.1\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    shuffle_n: 2048\n",
      "    bucketing_strategy: fully_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2024-04-05 16:02:27 nemo_logging:393] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /disk1/NVIDIA/datasets/LibriSpeech_NeMo/librivox-dev-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    use_start_end_token: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2024-04-05 16:02:27 nemo_logging:393] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    use_start_end_token: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-04-05 16:02:27 nemo_logging:381] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-04-05 16:02:31 nemo_logging:393] `method_cfg` is deprecated and will be removed in the future. Please use `measure_cfg` instead.\n",
      "[NeMo W 2024-04-05 16:02:31 nemo_logging:393] Re-writing `measure_cfg` with the value of `method_cfg`.\n",
      "[NeMo W 2024-04-05 16:02:31 nemo_logging:393] `temperature` is deprecated and will be removed in the future. Please use `alpha` instead.\n",
      "[NeMo W 2024-04-05 16:02:31 nemo_logging:393] Re-writing `alpha` with the value of `temperature`.\n",
      "[NeMo W 2024-04-05 16:02:31 nemo_logging:393] `method_cfg` is deprecated and will be removed in the future. Please use `measure_cfg` instead.\n",
      "[NeMo W 2024-04-05 16:02:31 nemo_logging:393] Re-writing `measure_cfg` with the value of `method_cfg`.\n",
      "[NeMo W 2024-04-05 16:02:31 nemo_logging:393] `temperature` is deprecated and will be removed in the future. Please use `alpha` instead.\n",
      "[NeMo W 2024-04-05 16:02:31 nemo_logging:393] Re-writing `alpha` with the value of `temperature`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-04-05 16:02:34 nemo_logging:381] Model EncDecCTCModelBPE was successfully restored from C:\\Users\\spn\\.cache\\huggingface\\hub\\models--nvidia--parakeet-ctc-0.6b\\snapshots\\097ffc5b027beabc73acb627def2d1d278e774e9\\parakeet-ctc-0.6b.nemo.\n"
     ]
    }
   ],
   "source": [
    "from models.nllb import nllb\n",
    "from models.TTS_utils import xtts_v2\n",
    "from models.parakeet import parakeet_ctc_model\n",
    "from models.es_fastconformer import stt_es_model\n",
    "model_nllb, tokinizer_nllb = nllb()\n",
    "xtts_v2_model = xtts_v2()\n",
    "parakeet = parakeet_ctc_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing audio_segments\\segment_0.wav...\n",
      "Processing segment...\n",
      "0.008033717\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_1.wav...\n",
      "Processing segment...\n",
      "0.00787304\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_2.wav...\n",
      "Processing segment...\n",
      "0.0072668944\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_3.wav...\n",
      "Processing segment...\n",
      "0.0040006344\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_4.wav...\n",
      "Processing segment...\n",
      "0.0074838432\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_5.wav...\n",
      "Processing segment...\n",
      "0.005566763\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_6.wav...\n",
      "Processing segment...\n",
      "0.006983923\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_7.wav...\n",
      "Processing segment...\n",
      "0.008073234\n",
      "No speech detected.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstream_VAD\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stream\n\u001b[1;32m----> 2\u001b[0m \u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparakeet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_nllb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokinizer_nllb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43menglish\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspanish\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\spn\\Desktop\\IE_Last_year\\main_capstone\\stream_VAD.py:155\u001b[0m, in \u001b[0;36mstream\u001b[1;34m(asr_model, model_nllb, tokinizer_nllb, source_lang, target_lang)\u001b[0m\n\u001b[0;32m    151\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(result_dir)\n\u001b[0;32m    153\u001b[0m executor \u001b[38;5;241m=\u001b[39m ThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Adjust the number of workers as per your requirement\u001b[39;00m\n\u001b[1;32m--> 155\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvad_collector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCHUNK_DURATION_MS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPADDING_DURATION_MS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_segements\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegments_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msegment_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_results\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresult_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\spn\\Desktop\\IE_Last_year\\main_capstone\\stream_VAD.py:36\u001b[0m, in \u001b[0;36mvad_collector\u001b[1;34m(sample_rate, frame_duration_ms, padding_duration_ms, vad, frames)\u001b[0m\n\u001b[0;32m     33\u001b[0m triggered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     35\u001b[0m voiced_frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 36\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_speech\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_speech\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtriggered\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\spn\\Desktop\\IE_Last_year\\main_capstone\\stream_VAD.py:144\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    142\u001b[0m stream \u001b[38;5;241m=\u001b[39m audio\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mFORMAT, channels\u001b[38;5;241m=\u001b[39mCHANNELS, rate\u001b[38;5;241m=\u001b[39mRATE, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, frames_per_buffer\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m160\u001b[39m)\n\u001b[0;32m    143\u001b[0m frames \u001b[38;5;241m=\u001b[39m read_audio(stream, CHUNK_DURATION_MS, RATE)\n\u001b[1;32m--> 144\u001b[0m frames \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m segments_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio_segments\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    147\u001b[0m result_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\spn\\Desktop\\IE_Last_year\\main_capstone\\stream_VAD.py:27\u001b[0m, in \u001b[0;36mread_audio\u001b[1;34m(stream, frame_duration_ms, rate)\u001b[0m\n\u001b[0;32m     25\u001b[0m frames_per_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(rate \u001b[38;5;241m*\u001b[39m frame_duration_ms \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes_per_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\spn\\anaconda3\\envs\\capstone\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from stream_VAD import stream\n",
    "stream(parakeet, model_nllb, tokinizer_nllb, \"english\", \"spanish\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
