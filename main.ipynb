{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-03-31 23:42:10 nemo_logging:393] Could not import NeMo NLP collection which is required for speech translation model.\n"
     ]
    }
   ],
   "source": [
    "from nllb import nllb\n",
    "from TTS_utils import xtts_v2\n",
    "from parakeet import parakeet_ctc_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2647ae83278448d9f70a6274aa442c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49073538053428ab804310bf2a0fc1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa44360f24724b2bb006392ce51c2cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e5e90dbd2341b19bcd9c47424b752e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/3.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "386212b75ec647b3b61884d3083a2359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/808 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e9eb5c02884774bf4f209f16890ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/5.48G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27684f6d0bc0436aac8aa6630e0d1a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/multilingual/multi-dataset/xtts_v2 is already downloaded.\n",
      " > Using model: xtts\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d74f7d5dc24c47c3b4dd8cb290732c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parakeet-ctc-0.6b.nemo:   0%|          | 0.00/2.44G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-31 23:46:34 nemo_logging:381] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-03-31 23:46:35 nemo_logging:393] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /disk1/NVIDIA/datasets/LibriSpeech_NeMo/librivox-train-all.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 16.7\n",
      "    min_duration: 0.1\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    shuffle_n: 2048\n",
      "    bucketing_strategy: fully_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2024-03-31 23:46:35 nemo_logging:393] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /disk1/NVIDIA/datasets/LibriSpeech_NeMo/librivox-dev-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    use_start_end_token: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2024-03-31 23:46:35 nemo_logging:393] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    use_start_end_token: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-31 23:46:35 nemo_logging:381] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-03-31 23:46:43 nemo_logging:393] `method_cfg` is deprecated and will be removed in the future. Please use `measure_cfg` instead.\n",
      "[NeMo W 2024-03-31 23:46:43 nemo_logging:393] Re-writing `measure_cfg` with the value of `method_cfg`.\n",
      "[NeMo W 2024-03-31 23:46:43 nemo_logging:393] `temperature` is deprecated and will be removed in the future. Please use `alpha` instead.\n",
      "[NeMo W 2024-03-31 23:46:43 nemo_logging:393] Re-writing `alpha` with the value of `temperature`.\n",
      "[NeMo W 2024-03-31 23:46:43 nemo_logging:393] `method_cfg` is deprecated and will be removed in the future. Please use `measure_cfg` instead.\n",
      "[NeMo W 2024-03-31 23:46:43 nemo_logging:393] Re-writing `measure_cfg` with the value of `method_cfg`.\n",
      "[NeMo W 2024-03-31 23:46:43 nemo_logging:393] `temperature` is deprecated and will be removed in the future. Please use `alpha` instead.\n",
      "[NeMo W 2024-03-31 23:46:43 nemo_logging:393] Re-writing `alpha` with the value of `temperature`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-31 23:46:46 nemo_logging:381] Model EncDecCTCModelBPE was successfully restored from C:\\Users\\spn\\.cache\\huggingface\\hub\\models--nvidia--parakeet-ctc-0.6b\\snapshots\\097ffc5b027beabc73acb627def2d1d278e774e9\\parakeet-ctc-0.6b.nemo.\n"
     ]
    }
   ],
   "source": [
    "model_nllb, tokinizer_nllb = nllb()\n",
    "xtts_v2_model = xtts_v2()\n",
    "parakeet = parakeet_ctc_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncDecCTCModelBPE(\n",
       "  (preprocessor): AudioToMelSpectrogramPreprocessor(\n",
       "    (featurizer): FilterbankFeatures()\n",
       "  )\n",
       "  (encoder): ConformerEncoder(\n",
       "    (pre_encode): ConvSubsampling(\n",
       "      (out): Linear(in_features=2560, out_features=1024, bias=True)\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
       "        (6): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (7): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (pos_enc): RelPositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x ConformerLayer(\n",
       "        (norm_feed_forward1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward1): ConformerFeedForward(\n",
       "          (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (activation): Swish()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (norm_conv): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (conv): ConformerConvolution(\n",
       "          (pointwise_conv1): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,))\n",
       "          (depthwise_conv): CausalConv1D(1024, 1024, kernel_size=(9,), stride=(1,), groups=1024)\n",
       "          (batch_norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): Swish()\n",
       "          (pointwise_conv2): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (norm_self_att): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attn): RelPositionMultiHeadAttention(\n",
       "          (linear_q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (linear_k): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (linear_out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear_pos): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (norm_feed_forward2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward2): ConformerFeedForward(\n",
       "          (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (activation): Swish()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (norm_out): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): ConvASRDecoder(\n",
       "    (decoder_layers): Sequential(\n",
       "      (0): Conv1d(1024, 1025, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       "  (loss): CTCLoss()\n",
       "  (spec_augmentation): SpectrogramAugmentation(\n",
       "    (spec_augment): SpecAugment()\n",
       "  )\n",
       "  (_wer): WERBPE()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model_nllb.to(device)\n",
    "xtts_v2_model.to(device)\n",
    "parakeet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nllb, tokinizer_nllb = nllb()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿ Qué pasa?\n"
     ]
    }
   ],
   "source": [
    "from nllb import nllb_translate\n",
    "\n",
    "translation = nllb_translate(model_nllb, tokinizer_nllb, \"Hello\", \"spanish\")\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing audio_segments\\segment_0.wav...\n",
      "Processing segment...\n",
      "Noise reduction done!\n",
      "Noise removal time: 0.06700921058654785\n",
      "Noise removed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4275120334754e16ac16bbcc019eeed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: of\n",
      "Transcription time: 1.2449307441711426\n",
      "Translation: de las\n",
      "Translation time: 1.340113878250122\n",
      "Processing TTS...\n",
      " > Text splitted to sentences.\n",
      "['de las']\n",
      "Writing audio_segments\\segment_1.wav...\n",
      "Processing segment...\n",
      "Noise reduction done!\n",
      "Noise removal time: 0.08846831321716309\n",
      "Noise removed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0feed865034222b9bf3dc31703c4ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: no said the fucker\n",
      "Transcription time: 0.43282651901245117\n",
      "Translation: No, dijo el cabrón.\n",
      "Translation time: 3.0404043197631836\n",
      "Processing TTS...\n",
      " > Text splitted to sentences.\n",
      "['No, dijo el cabrón.']\n",
      "Writing audio_segments\\segment_2.wav...\n",
      "Writing audio_segments\\segment_3.wav...\n",
      "Writing audio_segments\\segment_4.wav...\n",
      "Writing audio_segments\\segment_5.wav...\n",
      " > Processing time: 9.675014972686768\n",
      " > Real-time factor: 3.8391534722815868\n",
      "TTS done.\n",
      "TTS time: 9.699312210083008\n",
      "Processing segment...\n",
      "Noise reduction done!\n",
      "Noise removal time: 0.10106205940246582\n",
      "Noise removed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a11403c9f3400aa94b5b4db6459744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: stop doing this process\n",
      "Transcription time: 0.4670724868774414\n",
      "Translation: Deja de hacer este proceso\n",
      "Translation time: 2.781489133834839\n",
      "Processing TTS...\n",
      " > Text splitted to sentences.\n",
      "['Deja de hacer este proceso']\n",
      " > Processing time: 22.15000033378601\n",
      " > Real-time factor: 3.5992771147269007\n",
      "TTS done.\n",
      "TTS time: 22.208486080169678\n",
      "Processing segment...\n",
      "Noise reduction done!\n",
      "Noise removal time: 0.07973122596740723\n",
      "Noise removed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f438f917ad8f411b93184a39d95ffa98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: no\n",
      "Transcription time: 0.3994925022125244\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstream_VAD\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stream\n\u001b[1;32m----> 2\u001b[0m \u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparakeet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_nllb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokinizer_nllb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxtts_v2_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\spn\\Desktop\\IE_Last_year\\main_capstone\\stream_VAD.py:120\u001b[0m, in \u001b[0;36mstream\u001b[1;34m(parakeet, model_nllb, tokinizer_nllb, tts_model)\u001b[0m\n\u001b[0;32m    116\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(result_dir)\n\u001b[0;32m    118\u001b[0m executor \u001b[38;5;241m=\u001b[39m ThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Adjust the number of workers as per your requirement\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvad_collector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCHUNK_DURATION_MS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPADDING_DURATION_MS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_segements\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegments_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msegment_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_results\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresult_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\spn\\Desktop\\IE_Last_year\\main_capstone\\stream_VAD.py:33\u001b[0m, in \u001b[0;36mvad_collector\u001b[1;34m(sample_rate, frame_duration_ms, padding_duration_ms, vad, frames)\u001b[0m\n\u001b[0;32m     30\u001b[0m triggered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     32\u001b[0m voiced_frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 33\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_speech\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_speech\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtriggered\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\spn\\Desktop\\IE_Last_year\\main_capstone\\stream_VAD.py:109\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    107\u001b[0m stream \u001b[38;5;241m=\u001b[39m audio\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mFORMAT, channels\u001b[38;5;241m=\u001b[39mCHANNELS, rate\u001b[38;5;241m=\u001b[39mRATE, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, frames_per_buffer\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m160\u001b[39m)\n\u001b[0;32m    108\u001b[0m frames \u001b[38;5;241m=\u001b[39m read_audio(stream, CHUNK_DURATION_MS, RATE)\n\u001b[1;32m--> 109\u001b[0m frames \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m segments_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio_segments\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    112\u001b[0m result_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\spn\\Desktop\\IE_Last_year\\main_capstone\\stream_VAD.py:24\u001b[0m, in \u001b[0;36mread_audio\u001b[1;34m(stream, frame_duration_ms, rate)\u001b[0m\n\u001b[0;32m     22\u001b[0m frames_per_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(rate \u001b[38;5;241m*\u001b[39m frame_duration_ms \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes_per_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\spn\\anaconda3\\envs\\capstone\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: No es\n",
      "Translation time: 1.6941444873809814\n",
      "Processing TTS...\n",
      " > Text splitted to sentences.\n",
      "['No es']\n",
      " > Processing time: 12.446199417114258\n",
      " > Real-time factor: 4.849425663474862\n",
      "TTS done.\n",
      "TTS time: 12.473605155944824\n",
      "Processing segment...\n",
      "Noise reduction done!\n",
      "Noise removal time: 0.07497239112854004\n",
      "Noise removed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc40e3de7de94462807bcf252c529d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: stop\n",
      "Transcription time: 0.6778686046600342\n",
      " > Processing time: 7.46113395690918\n",
      " > Real-time factor: 3.8933643447048327\n",
      "TTS done.\n",
      "TTS time: 7.4796977043151855\n",
      "Processing segment...\n",
      "Noise reduction done!\n",
      "Noise removal time: 0.08081984519958496\n",
      "Noise removed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998372024c67433d8ca87523c85a26d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: do not transfer anymore\n",
      "Transcription time: 0.48453521728515625\n",
      "Translation: No lo hagas.\n",
      "Translation time: 2.822075843811035\n",
      "Processing TTS...\n",
      " > Text splitted to sentences.\n",
      "['No lo hagas.']\n",
      "Translation: No se transfiera más\n",
      "Translation time: 2.7834577560424805\n",
      "Processing TTS...\n",
      " > Text splitted to sentences.\n",
      "['No se transfiera más']\n",
      " > Processing time: 5.3007471561431885\n",
      " > Real-time factor: 3.2831874941841943\n",
      "TTS done.\n",
      "TTS time: 5.321718454360962\n",
      " > Processing time: 6.182507753372192\n",
      " > Real-time factor: 2.9906172332804677\n",
      "TTS done.\n",
      "TTS time: 6.213528871536255\n"
     ]
    }
   ],
   "source": [
    "from stream_VAD import stream\n",
    "stream(parakeet,model_nllb, tokinizer_nllb, xtts_v2_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-03-24 18:10:35 nemo_logging:393] C:\\Users\\spn\\AppData\\Local\\Temp\\ipykernel_23672\\462006554.py:4: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "      rate, data = wavfile.read(\"audio_segments/segment_10.wav\")\n",
      "    \n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
