{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-04-09 11:34:27 nemo_logging:381] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-04-09 11:34:27 nemo_logging:393] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /disk1/NVIDIA/datasets/LibriSpeech_NeMo/librivox-train-all.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 16.7\n",
      "    min_duration: 0.1\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    shuffle_n: 2048\n",
      "    bucketing_strategy: fully_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2024-04-09 11:34:27 nemo_logging:393] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /disk1/NVIDIA/datasets/LibriSpeech_NeMo/librivox-dev-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    use_start_end_token: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2024-04-09 11:34:27 nemo_logging:393] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    use_start_end_token: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-04-09 11:34:27 nemo_logging:381] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-04-09 11:34:31 nemo_logging:393] `method_cfg` is deprecated and will be removed in the future. Please use `measure_cfg` instead.\n",
      "[NeMo W 2024-04-09 11:34:31 nemo_logging:393] Re-writing `measure_cfg` with the value of `method_cfg`.\n",
      "[NeMo W 2024-04-09 11:34:31 nemo_logging:393] `temperature` is deprecated and will be removed in the future. Please use `alpha` instead.\n",
      "[NeMo W 2024-04-09 11:34:31 nemo_logging:393] Re-writing `alpha` with the value of `temperature`.\n",
      "[NeMo W 2024-04-09 11:34:31 nemo_logging:393] `method_cfg` is deprecated and will be removed in the future. Please use `measure_cfg` instead.\n",
      "[NeMo W 2024-04-09 11:34:31 nemo_logging:393] Re-writing `measure_cfg` with the value of `method_cfg`.\n",
      "[NeMo W 2024-04-09 11:34:31 nemo_logging:393] `temperature` is deprecated and will be removed in the future. Please use `alpha` instead.\n",
      "[NeMo W 2024-04-09 11:34:31 nemo_logging:393] Re-writing `alpha` with the value of `temperature`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-04-09 11:34:33 nemo_logging:381] Model EncDecCTCModelBPE was successfully restored from C:\\Users\\spn\\.cache\\huggingface\\hub\\models--nvidia--parakeet-ctc-0.6b\\snapshots\\097ffc5b027beabc73acb627def2d1d278e774e9\\parakeet-ctc-0.6b.nemo.\n"
     ]
    }
   ],
   "source": [
    "from models.nllb import nllb\n",
    "#from models.TTS_utils import xtts_v2\n",
    "from models.parakeet import parakeet_ctc_model\n",
    "from models.es_fastconformer import stt_es_model\n",
    "model_nllb, tokinizer_nllb = nllb()\n",
    "#xtts_v2_model = xtts_v2()\n",
    "parakeet = parakeet_ctc_model()\n",
    "#sst = stt_es_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing audio_segments\\segment_0.wav...\n",
      "Processing segment...\n",
      "0.014767605\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_1.wav...\n",
      "Processing segment...\n",
      "0.027705649\n",
      "Noise reduction done!\n",
      "Noise removed. Time: 0.06096482276916504\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86697ddff4c7446188d02939b9087cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: mud looks very sexy today i have to say\n",
      "Transcription time: 0.7386236190795898\n",
      "Translating...\n",
      "Processing translation...\n",
      "Writing audio_segments\\segment_2.wav...\n",
      "Processing segment...\n",
      "0.0031501611\n",
      "No speech detected.\n",
      "Translation: El barro se ve muy sexy hoy tengo que decir\n",
      "Translation time: 5.632938385009766\n",
      "Writing audio_segments\\segment_3.wav...\n",
      "Processing segment...\n",
      "0.027554423\n",
      "Noise reduction done!\n",
      "Noise removed. Time: 0.056884050369262695\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d565975fa787418f832fad20703632de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: wait what oneed uh saying it about\n",
      "Transcription time: 0.8167359828948975\n",
      "Translating...\n",
      "Processing translation...\n",
      "Writing audio_segments\\segment_4.wav...\n",
      "Processing segment...\n",
      "0.001578607\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_5.wav...\n",
      "Processing segment...\n",
      "0.00036590375\n",
      "No speech detected.\n",
      "Translation: Espera, ¿qué dice uno?\n",
      "Translation time: 5.394032955169678\n",
      "Writing audio_segments\\segment_6.wav...\n",
      "Processing segment...\n",
      "0.001001364\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_7.wav...\n",
      "Processing segment...\n",
      "0.0009879525\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_8.wav...\n",
      "Processing segment...\n",
      "0.024573863\n",
      "Noise reduction done!\n",
      "Noise removed. Time: 0.0438237190246582\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba8387cca4c24e68a2373e36a252828a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: does the model understand like if i say very complicated words like ubiquitous or some shit like that\n",
      "Transcription time: 0.6164824962615967\n",
      "Translating...\n",
      "Processing translation...\n",
      "Writing audio_segments\\segment_9.wav...\n",
      "Processing segment...\n",
      "0.0037742644\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_10.wav...\n",
      "Processing segment...\n",
      "0.00028811695\n",
      "No speech detected.\n",
      "Translation: ¿El modelo entiende como si yo dijera palabras muy complicadas como ubicua o alguna mierda así\n",
      "Translation time: 9.157487630844116\n",
      "Writing audio_segments\\segment_11.wav...\n",
      "Processing segment...\n",
      "0.0065927533\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_12.wav...\n",
      "Processing segment...\n",
      "0.0014854647\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_13.wav...\n",
      "Processing segment...\n",
      "0.00039781298\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_14.wav...\n",
      "Processing segment...\n",
      "0.005685532\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_15.wav...\n",
      "Processing segment...\n",
      "0.021991279\n",
      "Noise reduction done!\n",
      "Noise removed. Time: 0.05899834632873535\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e2999199dec497388f6d269d0d85185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: um uh i can't think of anything to say right now but the model is veryck the fact that it does it so quick is pretty pcking\n",
      "Transcription time: 0.9253618717193604\n",
      "Translating...\n",
      "Processing translation...\n",
      "Writing audio_segments\\segment_16.wav...\n",
      "Processing segment...\n",
      "0.0010401317\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_17.wav...\n",
      "Processing segment...\n",
      "0.008182182\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_18.wav...\n",
      "Processing segment...\n",
      "0.0017541209\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_19.wav...\n",
      "Processing segment...\n",
      "0.001483605\n",
      "No speech detected.\n",
      "Translation: No puedo pensar en nada que decir ahora mismo pero el modelo es muy bueno el hecho de que lo haga tan rápido es bastante pking\n",
      "Translation time: 11.7141273021698\n",
      "Writing audio_segments\\segment_20.wav...\n",
      "Processing segment...\n",
      "0.0005770982\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_21.wav...\n",
      "Processing segment...\n",
      "0.013108416\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_22.wav...\n",
      "Processing segment...\n",
      "0.00042562833\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_23.wav...\n",
      "Processing segment...\n",
      "0.00034161922\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_24.wav...\n",
      "Processing segment...\n",
      "0.0005093966\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_25.wav...\n",
      "Processing segment...\n",
      "0.0061648395\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_26.wav...\n",
      "Processing segment...\n",
      "0.006572231\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_27.wav...\n",
      "Processing segment...\n",
      "0.042306036\n",
      "Noise reduction done!\n",
      "Noise removed. Time: 0.03426384925842285\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d89cefee754aaebe06a1cbaa98fe7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: oh it doesn't detect you it only detects me how does that work\n",
      "Transcription time: 0.6948015689849854\n",
      "Translating...\n",
      "Processing translation...\n",
      "Translation: No te detecta a ti, sólo me detecta a mí. ¿Cómo funciona eso?\n",
      "Translation time: 8.392017602920532\n",
      "Writing audio_segments\\segment_28.wav...\n",
      "Processing segment...\n",
      "0.03018789\n",
      "Noise reduction done!\n",
      "Noise removed. Time: 0.07212185859680176\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d47e31bddbc44889afeb1e0abd5e1e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: no that's the same so it only okay so it's so you are you did implement that as well personalized what how does this work\n",
      "Transcription time: 0.8500344753265381\n",
      "Translating...\n",
      "Processing translation...\n",
      "Writing audio_segments\\segment_29.wav...\n",
      "Processing segment...\n",
      "0.0003926682\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_30.wav...\n",
      "Processing segment...\n",
      "0.0019510669\n",
      "No speech detected.\n",
      "Translation: No es lo mismo así que sólo está bien así que es así que usted es que implementar que también personalizado lo que cómo funciona esto\n",
      "Translation time: 11.493578910827637\n",
      "Writing audio_segments\\segment_31.wav...\n",
      "Processing segment...\n",
      "0.009128094\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_32.wav...\n",
      "Processing segment...\n",
      "0.027653633\n",
      "Noise reduction done!\n",
      "Noise removed. Time: 0.031007051467895508\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65cae09255a740c0b016818aa0dd61d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: like let's be honest it sounds nothing like how i would sound like if i spoke spanish\n",
      "Transcription time: 0.678830623626709\n",
      "Translating...\n",
      "Processing translation...\n",
      "Writing audio_segments\\segment_33.wav...\n",
      "Processing segment...\n",
      "0.0046893354\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_34.wav...\n",
      "Processing segment...\n",
      "0.06021975\n",
      "Noise reduction done!\n",
      "Noise removed. Time: 0.031163692474365234\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b47bb8f1164d36aee61d1c2c66f810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: Como si fuéramos honestos no suena nada como lo que yo sonaría si hablara español\n",
      "Translation time: 8.787926197052002\n",
      "Transcription: i can hear i can hear it i can hear it but it's not very\n",
      "Transcription time: 0.8225600719451904\n",
      "Translating...\n",
      "Processing translation...\n",
      "Writing audio_segments\\segment_35.wav...\n",
      "Processing segment...\n",
      "0.018667227\n",
      "Noise reduction done!\n",
      "Noise removed. Time: 0.035228729248046875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c21ab577f04cdc82ef98b5ae0a1dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: like it doesn't sound very naturally like\n",
      "Transcription time: 1.2723565101623535\n",
      "Translating...\n",
      "Processing translation...\n",
      "Writing audio_segments\\segment_36.wav...\n",
      "Writing audio_segments\\segment_37.wav...\n",
      "Translation: Puedo oírlo puedo oírlo puedo oírlo pero no es muy\n",
      "Translation time: 12.200790405273438\n",
      "Processing segment...\n",
      "0.0028318912\n",
      "No speech detected.\n",
      "Processing segment...\n",
      "0.0017479158\n",
      "No speech detected.\n",
      "Translation: No suena muy natural.\n",
      "Translation time: 7.904364585876465\n",
      "Writing audio_segments\\segment_38.wav...\n",
      "Processing segment...\n",
      "0.04291995\n",
      "Noise reduction done!\n",
      "Noise removed. Time: 0.05102849006652832\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb7b65eba44743f88b9f23dc35b4e249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: i sound very spanish like i s evo i sound bad spanish\n",
      "Transcription time: 0.5118186473846436\n",
      "Translating...\n",
      "Processing translation...\n",
      "Writing audio_segments\\segment_39.wav...\n",
      "Processing segment...\n",
      "0.0035247055\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_40.wav...\n",
      "Processing segment...\n",
      "0.013543322\n",
      "No speech detected.\n",
      "Writing audio_segments\\segment_41.wav...\n",
      "Processing segment...\n",
      "0.02601345\n",
      "Noise reduction done!\n",
      "Noise removed. Time: 0.03495216369628906\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91bc2fe133b54b8cabf4614094e2ec01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: Sueno muy español como yo. Sueno mal español.\n",
      "Translation time: 9.424434900283813\n",
      "Transcription: so if you could somehow my accent\n",
      "Transcription time: 0.7121782302856445\n",
      "Translating...\n",
      "Processing translation...\n",
      "Writing audio_segments\\segment_42.wav...\n",
      "Processing segment...\n",
      "0.008653474\n",
      "No speech detected.\n",
      "Translation: Así que si pudieras de alguna manera mi acento\n",
      "Translation time: 9.042868614196777\n",
      "Writing audio_segments\\segment_43.wav...\n",
      "Processing segment...\n",
      "0.019013062\n",
      "Noise reduction done!\n",
      "Noise removed. Time: 0.07289695739746094\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0b5b59b9ad74341ac9c6e56cf6eda2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: \n",
      "Transcription time: 0.7141587734222412\n",
      "Translating...\n",
      "Processing translation...\n",
      "Translation: - ¿ Qué?\n",
      "Translation time: 2.6520514488220215\n",
      "Writing audio_segments\\segment_44.wav...\n",
      "Processing segment...\n",
      "0.017020606\n",
      "Noise reduction done!\n",
      "Noise removed. Time: 0.037042856216430664\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7292255f43ab4c19ba56778d740d3a1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: i know think my and my opiew\n",
      "Transcription time: 0.1992795467376709\n",
      "Translating...\n",
      "Processing translation...\n",
      "Writing audio_segments\\segment_45.wav...\n",
      "Processing segment...\n",
      "0.011718195\n",
      "No speech detected.\n",
      "Translation: Yo sé que piensas mi y mi opview\n",
      "Translation time: 6.373355388641357\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstream_VAD\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stream\n\u001b[1;32m----> 2\u001b[0m \u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparakeet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_nllb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokinizer_nllb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43menglish\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspanish\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecord_temp.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecord_per.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\spn\\Desktop\\IE_Last_year\\main_capstone\\stream_VAD.py:158\u001b[0m, in \u001b[0;36mstream\u001b[1;34m(asr_model, model_nllb, tokinizer_nllb, source_lang, target_lang, json_file_temp, json_file_record)\u001b[0m\n\u001b[0;32m    154\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(result_dir)\n\u001b[0;32m    156\u001b[0m executor \u001b[38;5;241m=\u001b[39m ThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Adjust the number of workers as per your requirement\u001b[39;00m\n\u001b[1;32m--> 158\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvad_collector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCHUNK_DURATION_MS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPADDING_DURATION_MS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_segements\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegments_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msegment_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_results\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresult_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\spn\\Desktop\\IE_Last_year\\main_capstone\\stream_VAD.py:36\u001b[0m, in \u001b[0;36mvad_collector\u001b[1;34m(sample_rate, frame_duration_ms, padding_duration_ms, vad, frames)\u001b[0m\n\u001b[0;32m     33\u001b[0m triggered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     35\u001b[0m voiced_frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 36\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_speech\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_speech\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtriggered\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\spn\\Desktop\\IE_Last_year\\main_capstone\\stream_VAD.py:147\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    145\u001b[0m stream \u001b[38;5;241m=\u001b[39m audio\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mFORMAT, channels\u001b[38;5;241m=\u001b[39mCHANNELS, rate\u001b[38;5;241m=\u001b[39mRATE, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, frames_per_buffer\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m160\u001b[39m)\n\u001b[0;32m    146\u001b[0m frames \u001b[38;5;241m=\u001b[39m read_audio(stream, CHUNK_DURATION_MS, RATE)\n\u001b[1;32m--> 147\u001b[0m frames \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m segments_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio_segments\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    150\u001b[0m result_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\spn\\Desktop\\IE_Last_year\\main_capstone\\stream_VAD.py:27\u001b[0m, in \u001b[0;36mread_audio\u001b[1;34m(stream, frame_duration_ms, rate)\u001b[0m\n\u001b[0;32m     25\u001b[0m frames_per_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(rate \u001b[38;5;241m*\u001b[39m frame_duration_ms \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes_per_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\spn\\anaconda3\\envs\\capstone\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from stream_VAD import stream\n",
    "stream(parakeet, model_nllb, tokinizer_nllb, \"english\", \"spanish\", 'record_temp.json', 'record_per.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
